% !TEX root = ../thesis-example.tex
%
\chapter{Natural Language Processing}
\label{sec:nlp}

\section{Grundlagen}
\label{sec:nlp:grundlagen}

Betrachtet man einen Satz in einer natürlichen Sprache, die im Rahmen dieser Arbeit auf Englisch festgelegt ist, so kann ein Computer dessen Inhalt nicht ohne Weiteres herauslesen. Hierfür bedarf es verschiedener Hilfsstrukturen und zusätzlicher Informationen. Als ersten Schritt bietet es sich an, den einzelnen Wörtern eines Satzes ihre Wortart zuzuordnen. Mit Wortart, alternativ auch Wortklasse oder zu englisch part-of-speech (POS), ist gemeint, wie ein Wort im Satz auftritt. Beispiele für Wortarten sind Nomen, Verb und Adjektiv. In dieser Arbeit wird das Tagset, also die Menge an Wortarten, aus der Penn Treebank verwendet. %TODO hier zitieren und evtl Tagset als Tabelle anzeigen
%TODO Außerdem Quelle für POS Informationen suchen oder Buch nehmen 
Der Satz
\begin{quote}
My dog also likes eating sausage.
\end{quote}
würde mit diesem Tagset also folgendermaßen annotiert werden:
\begin{quote}
My/PRP\$ dog/NN also/RB likes/VBZ eating/VBG sausage/NN ./.
\end{quote}
Wie ein Satz maschinell mit POS-Tags versehen werden kann wird in dieser Arbeit nicht weiter behandelt. 
Über diese zusätzliche Notation hinaus kann man erkennen, dass sich in der englischen Sprache oftmals mehrere Wörter als Gruppe oder als eine Komponente innerhalb des Satzes verhalten. So eine Gruppe wäre zum Beispiel die Nominalphrase \textit{My Dog} oder die Verbalphrase \textit{likes eating sausage}. Auch hier wird wieder die Annotation der Penn Treebank verwendet. %TODO Siehe Abbildung mit Phrase Tags
Der Satz, welcher sich aus der zusätzlichen Annotation ergibt, lautet:
\begin{lstlisting}
(S
  (NP (PRP$ My) (NN dog))
  (ADVP (RB also))
  (VP (VBZ likes)
    (S
      (VP (VBG eating)
        (NP (NN sausage)))))
  (. .))
\end{lstlisting}
%TODO hier noch Bäume reinbringen und Baum zeichnen!
Wie man am Beispiel erkennen kann, sind auch diverse Verschachtelungen dieser Komponenten möglich. Um diese Anordnungsstruktur innerhalb einer Sprache zu beschreiben, bieten sich kontextfreie Grammatiken an. Auf der linken Seite der Regeln befindet sich also ein Nichtterminalsymbol und auf der rechten Seite können sich beliebig viele Terminale und Nichtterminale befinden. Für die Verarbeitung unseres Beispielsatzes wurden unter anderem folgende Regeln verwendet: %Exkurs CFG?
\begin{lstlisting}
S -> NP ADVP VP .
NP -> PRP$ NN
PRP$ -> My
NN -> dog
\end{lstlisting}
Das Startsymbol für Grammatiken einer natürlichen Sprache ist oftmals \textit{S}, was als das englische Wort \textit{sentence} aufgefasst werden kann. %TODO zitat aus kapitel 12.2
Anhand dem vollständigen Regelsatz der Grammatik einer Sprache kann man theoretisch jeden grammatikalisch korrekten Satz dieser Sprache annotieren. Es gibt für diverse natürliche Sprache Sammlungen von annotierten Sätzen, diese werden Treebank oder Korpus genannt. Ein bekannter Korpus der englischen Sprache ist die Penn Treebank, aus welcher auch die hier verwendete Annotation stammt. Dieser Korpus wird vom Linguistic Data Consortium, mit Sitz in der Univertität von Pennsylvania, herausgegeben. %TODO https://www.ldc.upenn.edu/about#
%Er umfasst über 4,5 Millionen Wörter 
%TODO Recherche über PTB betreiben - aktuelle Infos bekommen - Seite 442 im Buch nochmal genauer anschauen
Im Rahmen des Penn Treebank Projekts wurden von 1989 bis 1992 über 4,5 Millionen Wörter der Treebank hinzugefügt. Die Texte hierfür stammen zu einem Großteil aus dem Wall Street Journal. Der Ursprung der Sätze in einer Treebank kann eine Rolle spielen, da Parser mit Hilfe von Treebanks trainiert werden. Dazu mehr in Kapitel ... %TODO verweis auf kapitel parser trainieren und zitat von paper ptb_info

\section{Syntaktisches Parsen}
\label{sec:nlp:syn-parsen}

Syntaktisches Parsen wird als die "Aufgabe des Erkennens eines Satzes und des Zuweisens einer syntaktischen Struktur" definiert. %TODO zitat s.461
Zum Einstieg in das Kapitel wird das Parsen als Suche betrachtet. Das Suchproblem besteht darin, aus allen möglichen Bäumen, welche sich mit der Grammatik generieren lassen, den korrekten Baum zur Eingabe zu finden. Der Suchraum wird also von der Grammatik festgelegt. Ein Baum ist korrekt, wenn \textit{S} die Wurzel ist und exakt die Eingabe abgedeckt wird. Anhand dieser zwei Merkmale kann die Suche gestaltet werden. Somit ergeben sich als grundlegende Ansätze die Top-Down und die Bottom-Up Suche. Beim Top-Down Verfahren wird mit dem Startsymbol \textit{S} begonnen und dieses mit den Regeln der Grammatik Schritt für Schritt erweitert. Bäume deren Blätter nicht auf die Eingabe passen werden abgelehnt. Die Bottom-Up Suche beginnt, dem Namen entsprechend, am anderen Ende des Baumes. Im ersten Schritt gibt es nur die Eingabeworte als Blätter. Es wird mit den rechten Seiten der Grammatikregeln der Baum nach oben gebaut. Hier kann also ein Baum ausgeschlossen werden, wenn seine obersten Knoten in keiner Kombination auf keiner rechten Seite einer Produktion vorkommen. %Der Vorteil des einen Ansatz entspricht in etwa dem Nachteil des anderen. 
So werden mit der Top-Down Suche keine Bäume gebaut die niemals das Start Symbol als Wurzel haben, dafür wird aber die Eingabe im Allgemeinen nicht abgedeckt. Beim Bottom-Up Ansatz verhält es sich genau andersherum. 
Das Hauptproblem, welches sich beim Finden des korrekten Baumes ergibt, ist die Mehrdeutigkeit. Zum einen können Wörter mehrdeutig sein, wie etwa das englische Wort \textit{book}, welches sowohl Verb als auch Nomen ist. Zum anderen, und für diesen Kontext relevanter, gibt es die strukturelle Mehrdeutigkeit. Ein Beispielsatz hierfür ist: 
\begin{quote}
I shot an elephant in my pajamas.
\end{quote}
In dieser Satzstruktur kann sich \textit{in my pajamas} sowohl auf den Erzähler, als auch auf den Elefanten beziehen und gibt es mehr als einen korrekten Baum. % Grammatikalisch sind also mehrere Bäume korrekt, inhaltlich aber nur einer. %TODO Hier besser ausdrücken
Diese Art der strukturellen Mehrdeutigkeit ist die Anhangs-Mehrdeutigkeit. Eine Komponente des Satzes, in diesem Fall die Präpostionalphrase, kann an mehreren Stellen angehängt werden. Kombiniert man die Präpositional- an die Verbalphrase hat der Satz die Bedeutung, dass das Schießen im Pyjama stattgefunden hat. Bindet man diese an das Nomen Elefant wird ausgesagt, dass dieser sich im Pyjama befindet. Grammatikalische Korrektheit ist in beiden Fällen gegeben. Eine andere Art ist die Koordinations-Mehrdeutigkeit, welche in Verbindung mit Konjunktionen und Satzverbindungen auftritt. Beispielsweise kann der Satzausschnitt \textit{old men and women} unterschiedlich interpretiert werden. \textit{Old} kann sich auf \textit{men and women} oder nur auf \textit{men} beziehen. Die Anzahl an unterschiedlichen und dennoch korrekten Bäumen für einen Satz kann also oft groß sein. %TODO kann sogar exponentiell wachsen, Seite 467
Von diesen Bäumen beschreibt aber nur einer den Inhalt des Satzes so, wie er vom Autor gemeint ist. Ein Parser braucht als weitere Kriterien um sich zwischen den verschiedenen Möglichkeiten entscheiden zu können. Hierzu mehr in Kapitel... %TODO Kapitel PCFG, etc..
Ohne zusätzliche Informationen kann der Parser nur alle möglichen Bäume erstellen. Um das effizient zu bewerkstelligen bietet sich dynamisches Programmieren an. 

\subsection{Dynamische Programmierung}
\label{sec:nlp:syn-parsen:dyn-progr}

Dynamisches Programmieren ist hier sinnvoll, da beim Erstellen des Baumes im Allgemeinen Mehrfacharbeit anfällt. 
